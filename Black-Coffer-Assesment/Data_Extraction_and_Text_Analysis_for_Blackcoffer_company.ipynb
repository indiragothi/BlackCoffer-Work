{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYCAhLyAhMbG",
        "outputId": "78af9138-4c17-436e-c821-961e29813593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 pandas nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtqFGDf8hUlG",
        "outputId": "1362f6aa-ba2d-4349-d4b7-96637171a065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa_ONewhIVLB",
        "outputId": "3f839225-2d1c-470e-d95e-d147794f75eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/My Drive/Black-Coffer/TitleText'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/My Drive/Black-Coffer/TitleText'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lNMH1gfF3cF",
        "outputId": "63ab6188-2d50-4f02-ab46-349b118d7a77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#import necessary pacakages\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj-SlUf1vTbE",
        "outputId": "7b45c926-a655-49e6-9b7b-66165045c914"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241017.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241018.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241019.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241020.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241021.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241022.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241023.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241024.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241025.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241026.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241027.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241028.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241029.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241030.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241031.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241032.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241033.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241034.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241035.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241036.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241037.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241038.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241039.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241040.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241041.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241042.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241043.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241044.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241045.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241046.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241047.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241048.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241049.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241050.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241051.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241052.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241053.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241054.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241055.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241056.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241057.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241058.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241059.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241060.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241061.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241062.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241063.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241064.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241065.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241066.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241067.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241068.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241069.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241070.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241071.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241072.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241073.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241074.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241075.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241076.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241077.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241078.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241079.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241080.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241081.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241082.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241083.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241084.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241085.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241086.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241087.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241088.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241089.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241090.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241091.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241092.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241093.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241094.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241095.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241096.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241097.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241098.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241099.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241100.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241101.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241102.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241103.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241104.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241105.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241106.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241107.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241108.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241109.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241110.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241111.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241112.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241113.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241114.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241115.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241116.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241117.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241118.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241119.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241120.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241121.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241122.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241123.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241124.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241125.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241126.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241127.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241128.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241129.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241130.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241131.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241132.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241133.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241134.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241135.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241136.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241137.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241138.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241139.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241140.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241141.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241142.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241143.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241144.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241145.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241146.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241147.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241148.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241149.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241150.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241151.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241152.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241153.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241154.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241155.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241156.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241157.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241158.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241159.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241160.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241161.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241162.txt\n",
            "Saved: /content/drive/My Drive/Black-Coffer/TitleText/TitleText_Netclan20241163.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Read Excel file\n",
        "df = pd.read_excel(\"/content/drive/My Drive/Black-Coffer/Input.xlsx\")\n",
        "\n",
        "# Define the folder path\n",
        "folder_path = \"/content/drive/My Drive/Black-Coffer/TitleText\"\n",
        "\n",
        "# Ensure the folder exists\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "# Loop through each row\n",
        "for index, row in df.iterrows():\n",
        "    url = row['URL']\n",
        "    url_id = row['URL_ID']\n",
        "\n",
        "    # Make a request to the URL\n",
        "    headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()  # Check if request was successful\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching {url_id}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Create a BeautifulSoup object\n",
        "    try:\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    except Exception as e:\n",
        "        print(f\"Can't parse page of {url_id}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Find title\n",
        "    try:\n",
        "        title = soup.find('h1').get_text().strip()\n",
        "    except:\n",
        "        print(f\"Can't get title of {url_id}\")\n",
        "        title = \"No Title\"\n",
        "\n",
        "    # Find text\n",
        "    article = \"\"\n",
        "    try:\n",
        "        paragraphs = soup.find_all('p')\n",
        "        if not paragraphs:\n",
        "            print(f\"No paragraphs found for {url_id}\")\n",
        "        for p in paragraphs:\n",
        "            article += p.get_text() + \"\\n\"\n",
        "    except:\n",
        "        print(f\"Can't get text of {url_id}\")\n",
        "        article = \"No Content\"\n",
        "\n",
        "    # Define file path\n",
        "    file_name = os.path.join(folder_path, f\"TitleText_{url_id}.txt\")\n",
        "\n",
        "    # Write title and text to file\n",
        "    try:\n",
        "        with open(file_name, 'w', encoding='utf-8') as file:\n",
        "            file.write(title + '\\n' + article)\n",
        "        print(f\"Saved: {file_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing file for {url_id}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg-gWTIQ5iuA",
        "outputId": "2dc353d0-6d88-4aa8-e856-23d4035448fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tRdSv8ErMOm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Directories\n",
        "text_dir = \"/content/drive/My Drive/Black-Coffer/TitleText\"\n",
        "stopwords_dir = \"/content/drive/My Drive/Black-Coffer/StopWords\"\n",
        "sentment_dir = \"/content/drive/My Drive/Black-Coffer/MasterDictionary\"\n",
        "\n",
        "# load all stop words from the stopwords directory and store in the set variable\n",
        "stop_words = set()\n",
        "for files in os.listdir(stopwords_dir):\n",
        "  with open(os.path.join(stopwords_dir,files),'r',encoding='ISO-8859-1') as f:\n",
        "    stop_words.update(set(f.read().splitlines()))\n",
        "\n",
        "# load all text files  from the  directory and store in a list(docs)\n",
        "docs = []\n",
        "for text_file in os.listdir(text_dir):\n",
        "  with open(os.path.join(text_dir,text_file),'r') as f:\n",
        "    text = f.read()\n",
        "#tokenize the given text file\n",
        "    words = word_tokenize(text)\n",
        "# remove the stop words from the tokens\n",
        "    filtered_text = [word for word in words if word.lower() not in stop_words]\n",
        "# add each filtered tokens of each file into a list\n",
        "    docs.append(filtered_text)\n",
        "\n",
        "\n",
        "\n",
        "# store positive, Negative words from the directory\n",
        "pos=set()\n",
        "neg=set()\n",
        "\n",
        "for files in os.listdir(sentment_dir):\n",
        "  if files =='positive-words.txt':\n",
        "    with open(os.path.join(sentment_dir,files),'r',encoding='ISO-8859-1') as f:\n",
        "      pos.update(f.read().splitlines())\n",
        "  else:\n",
        "    with open(os.path.join(sentment_dir,files),'r',encoding='ISO-8859-1') as f:\n",
        "      neg.update(f.read().splitlines())\n",
        "\n",
        "# now collect the positive  and negative words from each file\n",
        "# calculate the scores from the positive and negative words\n",
        "positive_words = []\n",
        "Negative_words =[]\n",
        "positive_score = []\n",
        "negative_score = []\n",
        "polarity_score = []\n",
        "subjectivity_score = []\n",
        "\n",
        "#iterate through the list of docs\n",
        "for i in range(len(docs)):\n",
        "  positive_words.append([word for word in docs[i] if word.lower() in pos])\n",
        "  Negative_words.append([word for word in docs[i] if word.lower() in neg])\n",
        "  positive_score.append(len(positive_words[i]))\n",
        "  negative_score.append(len(Negative_words[i]))\n",
        "  polarity_score.append((positive_score[i] - negative_score[i]) / ((positive_score[i] + negative_score[i]) + 0.000001))\n",
        "  subjectivity_score.append((positive_score[i] + negative_score[i]) / ((len(docs[i])) + 0.000001))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "F8RaMuD_EnQQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Average Sentence Length = the number of words / the number of sentences\n",
        "# Percentage of Complex words = the number of complex words / the number of words\n",
        "# Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
        "\n",
        "avg_sentence_length = []\n",
        "Percentage_of_Complex_words  =  []\n",
        "Fog_Index = []\n",
        "complex_word_count =  []\n",
        "avg_syllable_word_count =[]\n",
        "\n",
        "stopwords = set(stopwords.words('english'))\n",
        "def measure(file):\n",
        "  with open(os.path.join(text_dir, file),'r') as f:\n",
        "    text = f.read()\n",
        "# remove punctuations\n",
        "    text = re.sub(r'[^\\w\\s.]','',text)\n",
        "# split the given text file into sentences\n",
        "    sentences = text.split('.')\n",
        "# total number of sentences in a file\n",
        "    num_sentences = len(sentences)\n",
        "# total words in the file\n",
        "    words = [word  for word in text.split() if word.lower() not in stopwords ]\n",
        "    num_words = len(words)\n",
        "\n",
        "# complex words having syllable count is greater than 2\n",
        "# Complex words are words in the text that contain more than two syllables.\n",
        "    complex_words = []\n",
        "    for word in words:\n",
        "      vowels = 'aeiou'\n",
        "      syllable_count_word = sum( 1 for letter in word if letter.lower() in vowels)\n",
        "      if syllable_count_word > 2:\n",
        "        complex_words.append(word)\n",
        "\n",
        "# Syllable Count Per Word\n",
        "# We count the number of Syllables in each word of the text by counting the vowels present in each word.\n",
        "#  We also handle some exceptions like words ending with \"es\",\"ed\" by not counting them as a syllable.\n",
        "    syllable_count = 0\n",
        "    syllable_words =[]\n",
        "    for word in words:\n",
        "      if word.endswith('es'):\n",
        "        word = word[:-2]\n",
        "      elif word.endswith('ed'):\n",
        "        word = word[:-2]\n",
        "      vowels = 'aeiou'\n",
        "      syllable_count_word = sum( 1 for letter in word if letter.lower() in vowels)\n",
        "      if syllable_count_word >= 1:\n",
        "        syllable_words.append(word)\n",
        "        syllable_count += syllable_count_word\n",
        "\n",
        "\n",
        "    avg_sentence_len = num_words / num_sentences\n",
        "    avg_syllable_word_count = syllable_count / len(syllable_words)\n",
        "    Percent_Complex_words  =  len(complex_words) / num_words\n",
        "    Fog_Index = 0.4 * (avg_sentence_len + Percent_Complex_words)\n",
        "\n",
        "    return avg_sentence_len, Percent_Complex_words, Fog_Index, len(complex_words),avg_syllable_word_count\n",
        "\n",
        "# iterate through each file or doc\n",
        "for file in os.listdir(text_dir):\n",
        "  x,y,z,a,b = measure(file)\n",
        "  avg_sentence_length.append(x)\n",
        "  Percentage_of_Complex_words.append(y)\n",
        "  Fog_Index.append(z)\n",
        "  complex_word_count.append(a)\n",
        "  avg_syllable_word_count.append(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4NElx7d94ICm"
      },
      "outputs": [],
      "source": [
        "# Word Count and Average Word Length Sum of the total number of characters in each word/Total number of words\n",
        "# We count the total cleaned words present in the text by\n",
        "# removing the stop words (using stopwords class of nltk package).\n",
        "# removing any punctuations like ? ! , . from the word before counting.\n",
        "\n",
        "def cleaned_words(file):\n",
        "  with open(os.path.join(text_dir,file), 'r') as f:\n",
        "    text = f.read()\n",
        "    text = re.sub(r'[^\\w\\s]', '' , text)\n",
        "    words = [word  for word in text.split() if word.lower() not in stopwords]\n",
        "    length = sum(len(word) for word in words)\n",
        "    average_word_length = length / len(words)\n",
        "  return len(words),average_word_length\n",
        "\n",
        "word_count = []\n",
        "average_word_length = []\n",
        "for file in os.listdir(text_dir):\n",
        "  x, y = cleaned_words(file)\n",
        "  word_count.append(x)\n",
        "  average_word_length.append(y)\n",
        "\n",
        "\n",
        "# To calculate Personal Pronouns mentioned in the text, we use regex to find\n",
        "# the counts of the words - “I,” “we,” “my,” “ours,” and “us”. Special care is taken\n",
        "#  so that the country name US is not included in the list.\n",
        "def count_personal_pronouns(file):\n",
        "  with open(os.path.join(text_dir,file), 'r') as f:\n",
        "    text = f.read()\n",
        "    personal_pronouns = [\"I\", \"we\", \"my\", \"ours\", \"us\"]\n",
        "    count = 0\n",
        "    for pronoun in personal_pronouns:\n",
        "      count += len(re.findall(r\"\\b\" + pronoun + r\"\\b\", text)) # \\b is used to match word boundaries\n",
        "  return count\n",
        "\n",
        "pp_count = []\n",
        "for file in os.listdir(text_dir):\n",
        "  x = count_personal_pronouns(file)\n",
        "  pp_count.append(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXsnVluZ9TG3",
        "outputId": "6a60dd4a-a1df-4e9b-a793-14c7ff2f1fdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame rows: 147\n",
            "Variable lengths: [147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147]\n",
            "Saved Output_Data.csv successfully!\n"
          ]
        }
      ],
      "source": [
        "# Load Output Data Structure\n",
        "output_df = pd.read_excel('/content/drive/My Drive/Black-Coffer/Output Data Structure.xlsx')\n",
        "\n",
        "# Drop rows where URL_ID does not exist\n",
        "output_df.set_index(\"URL_ID\", inplace=True)  # Ensure URL_ID is the index\n",
        "output_df.drop([44, 57, 144], errors='ignore', inplace=True)  # Ignore if not found\n",
        "output_df.reset_index(inplace=True)  # Reset index\n",
        "\n",
        "# Ensure variable lengths match\n",
        "print(\"DataFrame rows:\", len(output_df))\n",
        "print(\"Variable lengths:\", [len(var) for var in variables])\n",
        "\n",
        "# Assign values safely\n",
        "for i, var in enumerate(variables):\n",
        "    if len(var) == len(output_df):  # Ensure equal lengths\n",
        "        output_df.iloc[:, i+2] = var\n",
        "    else:\n",
        "        print(f\"Skipping column {i+2} due to length mismatch\")\n",
        "\n",
        "# Save the dataframe to CSV\n",
        "output_df.to_csv('/content/drive/My Drive/Black-Coffer/Output_Data.csv', index=False)\n",
        "print(\"Saved Output_Data.csv successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
